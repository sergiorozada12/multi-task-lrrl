{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Union\n",
    "import tensorly as tl\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import logger, spaces\n",
    "#from gymnasium.envs.classic_control import utils\n",
    "#from gym.error import DependencyNotInstalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_X = np.pi\n",
    "DEFAULT_Y = 1.0\n",
    "\n",
    "class PendulumEnv(gym.Env):\n",
    "    def __init__(self, g=10.0, m=1.0, l=1.0):\n",
    "        self.max_speed = 8\n",
    "        self.max_torque = 2.0\n",
    "        self.dt = 0.05\n",
    "        self.g = g\n",
    "        self.m = m\n",
    "        self.l = l\n",
    "\n",
    "        self.screen_dim = 500\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "\n",
    "        high = np.array([1.0, 1.0, self.max_speed], dtype=np.float32)\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-self.max_torque, high=self.max_torque, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(low=-high, high=high, dtype=np.float32)\n",
    "\n",
    "    def step(self, u):\n",
    "        th, thdot = self.state  # th := theta\n",
    "\n",
    "        g = self.g\n",
    "        m = self.m\n",
    "        l = self.l\n",
    "        dt = self.dt\n",
    "\n",
    "        u = np.clip(u, -self.max_torque, self.max_torque)[0]\n",
    "        self.last_u = u  # for rendering\n",
    "        # costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.001 * (u**2)\n",
    "        costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.1 * (u**2)\n",
    "\n",
    "        newthdot = thdot + (3 * g / (2 * l) * np.sin(th) + 3.0 / (m * l**2) * u) * dt\n",
    "        newthdot = np.clip(newthdot, -self.max_speed, self.max_speed)\n",
    "        newth = th + newthdot * dt\n",
    "\n",
    "        self.state = np.array([newth, newthdot])\n",
    "\n",
    "        return self._get_obs(), -costs, False, False, {}\n",
    "\n",
    "    def reset(self, *, seed: Optional[int] = None):\n",
    "        super().reset(seed=seed)\n",
    "        high = np.array([DEFAULT_X, DEFAULT_Y])\n",
    "        low = -high  # We enforce symmetric limits.\n",
    "        # self.state = self.np_random.uniform(low=low, high=high)\n",
    "        self.state = [np.random.rand()/100, np.random.rand()/100]\n",
    "        self.last_u = None\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        theta, thetadot = self.state\n",
    "        return np.array([theta, thetadot], dtype=np.float32)\n",
    "\n",
    "def angle_normalize(x):\n",
    "    return ((x + np.pi) % (2 * np.pi)) - np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discretizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_points_states,\n",
    "        max_points_states,\n",
    "        bucket_states,\n",
    "        min_points_actions,\n",
    "        max_points_actions,\n",
    "        bucket_actions,\n",
    "        ):\n",
    "        self.min_points_states = np.array(min_points_states)\n",
    "        self.max_points_states = np.array(max_points_states)\n",
    "        self.bucket_states = np.array(bucket_states)\n",
    "        self.range_states = self.max_points_states - self.min_points_states\n",
    "\n",
    "        self.min_points_actions = np.array(min_points_actions)\n",
    "        self.max_points_actions = np.array(max_points_actions)\n",
    "        self.bucket_actions = np.array(bucket_actions)\n",
    "        # Think this better\n",
    "        self.spacing_actions = (self.max_points_actions - self.min_points_actions) / (self.bucket_actions - 1)\n",
    "\n",
    "        self.range_actions = self.max_points_actions - self.min_points_actions\n",
    "\n",
    "        self.n_states = np.round(self.bucket_states).astype(int)\n",
    "        self.n_actions = np.round(self.bucket_actions).astype(int)\n",
    "        self.dimensions = np.concatenate((self.n_states, self.n_actions))\n",
    "\n",
    "    def get_state_index(self, state):\n",
    "        state = np.clip(state, a_min=self.min_points_states, a_max=self.max_points_states)\n",
    "        scaling = (state - self.min_points_states) / self.range_states\n",
    "        state_idx = np.round(scaling * (self.bucket_states - 1)).astype(int)\n",
    "        return tuple(state_idx.tolist())\n",
    "\n",
    "    def get_action_index(self, action):\n",
    "        action = np.clip(action, a_min=self.min_points_actions, a_max=self.max_points_actions)\n",
    "        scaling = (action - self.min_points_actions) / self.range_actions\n",
    "        action_idx = np.round(scaling * (self.bucket_actions - 1)).astype(int)\n",
    "        return tuple(action_idx.tolist())\n",
    "\n",
    "    def get_action_from_index(self, action_idx):\n",
    "        return self.min_points_actions + action_idx * self.spacing_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PARAFAC(torch.nn.Module):\n",
    "    def __init__(self, dims, k, scale=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.n_factors = len(dims)\n",
    "        self.factors = torch.nn.ParameterList([\n",
    "            torch.nn.Parameter(scale * torch.randn(dim, k, dtype=torch.double, requires_grad=True))\n",
    "            for dim in dims\n",
    "        ])\n",
    "\n",
    "    def forward(self, indices):\n",
    "        factor_vectors = []\n",
    "        for i in range(indices.shape[1]):\n",
    "            idx = indices[:, i]\n",
    "            factor_vectors.append(self.factors[i][idx, :])        \n",
    "        vectors = torch.stack(factor_vectors, dim=1)\n",
    "\n",
    "        prod = torch.prod(vectors, dim=1)\n",
    "\n",
    "        if indices.shape[1] < self.n_factors:\n",
    "            return torch.matmul(prod, self.factors[-1].T)\n",
    "\n",
    "        return torch.sum(prod, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(g, m, l):\n",
    "    env = PendulumEnv(g, m, l)\n",
    "    nS = 100\n",
    "    nA = 100\n",
    "\n",
    "    discretizer = Discretizer(\n",
    "        min_points_states=[-1, -5],\n",
    "        max_points_states=[1, 5],\n",
    "        bucket_states=[nS]*2,\n",
    "        min_points_actions=[-2],\n",
    "        max_points_actions=[2],\n",
    "        bucket_actions=[nA],\n",
    "    )\n",
    "\n",
    "    E = 10\n",
    "    H = 100\n",
    "\n",
    "    states, states_next, actions, rewards = [], [], [], []\n",
    "\n",
    "    for e in range(E):\n",
    "        s, _ = env.reset()\n",
    "        s_idx = discretizer.get_state_index(s)\n",
    "        for h in range(H):\n",
    "            a_idx = np.random.choice(nA)\n",
    "            a = discretizer.get_action_from_index(a_idx)\n",
    "            sp, r, d, _, _ = env.step(a)\n",
    "            sp_idx = discretizer.get_state_index(sp)\n",
    "\n",
    "            states.append(s_idx)\n",
    "            states_next.append(sp_idx)\n",
    "            actions.append(a_idx)\n",
    "            rewards.append(r)\n",
    "\n",
    "            if d:\n",
    "                break\n",
    "\n",
    "            s = sp\n",
    "            s_idx = sp_idx\n",
    "\n",
    "    states = torch.tensor(states)\n",
    "    states_next = torch.tensor(states_next)\n",
    "    actions = torch.tensor(actions)\n",
    "    rewards = torch.tensor(rewards)\n",
    "\n",
    "    return states, states_next, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories(Dataset):\n",
    "    def __init__(self):\n",
    "        g = 1\n",
    "        m = 1\n",
    "        l = 1\n",
    "        states, states_next, actions, rewards = sample_data(g, m, l)\n",
    "\n",
    "        self.states = states\n",
    "        self.states_next = states_next\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.states.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.states_next[idx], self.actions[idx], self.rewards[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = Trajectories()\n",
    "loader = DataLoader(trajectories, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 588.4302381198203\n",
      "Epoch: 1000 - Loss: 596.9661826456563\n",
      "Epoch: 2000 - Loss: 552.6919196358621\n",
      "Epoch: 3000 - Loss: 567.1644367941581\n",
      "Epoch: 4000 - Loss: 583.5478984179764\n",
      "Epoch: 5000 - Loss: 540.0473539063603\n",
      "Epoch: 6000 - Loss: 567.0153146576956\n",
      "Epoch: 7000 - Loss: 548.19113443123\n",
      "Epoch: 8000 - Loss: 509.55924348601343\n",
      "Epoch: 9000 - Loss: 562.2201398146664\n",
      "Epoch: 10000 - Loss: 539.0075959118395\n",
      "Epoch: 11000 - Loss: 517.9860721472979\n",
      "Epoch: 12000 - Loss: 490.899312343503\n",
      "Epoch: 13000 - Loss: 525.6712534108433\n",
      "Epoch: 14000 - Loss: 511.5800678330114\n",
      "Epoch: 15000 - Loss: 501.0618345011969\n",
      "Epoch: 16000 - Loss: 447.07817824491724\n",
      "Epoch: 17000 - Loss: 510.55864256125085\n",
      "Epoch: 18000 - Loss: 488.3741483099576\n",
      "Epoch: 19000 - Loss: 503.3242608158722\n",
      "Epoch: 20000 - Loss: 476.5784146968351\n",
      "Epoch: 21000 - Loss: 467.821385589561\n",
      "Epoch: 22000 - Loss: 477.4497286560654\n",
      "Epoch: 23000 - Loss: 461.58038179498857\n",
      "Epoch: 24000 - Loss: 436.6062626464272\n",
      "Epoch: 25000 - Loss: 459.45088482483055\n",
      "Epoch: 26000 - Loss: 466.7672911962227\n",
      "Epoch: 27000 - Loss: 461.542652379209\n",
      "Epoch: 28000 - Loss: 423.6454443626019\n",
      "Epoch: 29000 - Loss: 434.9139523466682\n",
      "Epoch: 30000 - Loss: 416.3317960759704\n",
      "Epoch: 31000 - Loss: 448.36388359978105\n",
      "Epoch: 32000 - Loss: 441.0396849909187\n",
      "Epoch: 33000 - Loss: 417.05247140106184\n",
      "Epoch: 34000 - Loss: 439.8411698729859\n",
      "Epoch: 35000 - Loss: 411.24518214828936\n",
      "Epoch: 36000 - Loss: 408.64130755670044\n",
      "Epoch: 37000 - Loss: 402.4087083243936\n",
      "Epoch: 38000 - Loss: 432.8869951407659\n",
      "Epoch: 39000 - Loss: 396.01742610674796\n",
      "Epoch: 40000 - Loss: 418.5724360869334\n",
      "Epoch: 41000 - Loss: 412.5814613278326\n",
      "Epoch: 42000 - Loss: 390.5697475073285\n",
      "Epoch: 43000 - Loss: 410.4137314127517\n",
      "Epoch: 44000 - Loss: 375.0827386035246\n",
      "Epoch: 45000 - Loss: 378.7451686415228\n",
      "Epoch: 46000 - Loss: 400.5339875670127\n",
      "Epoch: 47000 - Loss: 398.10102257199424\n",
      "Epoch: 48000 - Loss: 401.199549364755\n",
      "Epoch: 49000 - Loss: 399.5059476484736\n",
      "Epoch: 50000 - Loss: 387.4234072507448\n",
      "Epoch: 51000 - Loss: 406.6873107572618\n",
      "Epoch: 52000 - Loss: 386.89493980186893\n",
      "Epoch: 53000 - Loss: 412.59422686776685\n",
      "Epoch: 54000 - Loss: 417.0862056821428\n",
      "Epoch: 55000 - Loss: 400.9286687222481\n",
      "Epoch: 56000 - Loss: 364.0909068981757\n",
      "Epoch: 57000 - Loss: 397.7325262708004\n",
      "Epoch: 58000 - Loss: 384.156414872372\n",
      "Epoch: 59000 - Loss: 391.36089110556884\n",
      "Epoch: 60000 - Loss: 358.5141475930291\n",
      "Epoch: 61000 - Loss: 371.9913236118047\n",
      "Epoch: 62000 - Loss: 397.34534399144684\n",
      "Epoch: 63000 - Loss: 379.3659709849029\n",
      "Epoch: 64000 - Loss: 364.88814984649304\n",
      "Epoch: 65000 - Loss: 363.7307430071305\n",
      "Epoch: 66000 - Loss: 396.82581801271573\n",
      "Epoch: 67000 - Loss: 390.80362213787373\n",
      "Epoch: 68000 - Loss: 369.9005846026553\n",
      "Epoch: 69000 - Loss: 376.24993979034434\n",
      "Epoch: 70000 - Loss: 340.6949464001268\n",
      "Epoch: 71000 - Loss: 368.58229568763477\n",
      "Epoch: 72000 - Loss: 347.47450447129376\n",
      "Epoch: 73000 - Loss: 339.11478437948244\n",
      "Epoch: 74000 - Loss: 358.15606869853616\n",
      "Epoch: 75000 - Loss: 364.82929280315113\n",
      "Epoch: 76000 - Loss: 357.8922370153276\n",
      "Epoch: 77000 - Loss: 353.31911384572936\n",
      "Epoch: 78000 - Loss: 346.7957674975142\n",
      "Epoch: 79000 - Loss: 351.4097712484022\n",
      "Epoch: 80000 - Loss: 365.9506484906981\n",
      "Epoch: 81000 - Loss: 371.98097282030096\n",
      "Epoch: 82000 - Loss: 328.58167392388725\n",
      "Epoch: 83000 - Loss: 366.6173407078719\n",
      "Epoch: 84000 - Loss: 322.1993446979529\n",
      "Epoch: 85000 - Loss: 348.04508873048184\n",
      "Epoch: 86000 - Loss: 313.7560083561657\n",
      "Epoch: 87000 - Loss: 341.501081679203\n",
      "Epoch: 88000 - Loss: 359.92883317488577\n",
      "Epoch: 89000 - Loss: 352.199063039828\n",
      "Epoch: 90000 - Loss: 347.9695405696353\n",
      "Epoch: 91000 - Loss: 309.0806918515572\n",
      "Epoch: 92000 - Loss: 341.5595709439119\n",
      "Epoch: 93000 - Loss: 337.9682383854803\n",
      "Epoch: 94000 - Loss: 350.3533060996789\n",
      "Epoch: 95000 - Loss: 351.6281629128616\n",
      "Epoch: 96000 - Loss: 355.0748335904508\n",
      "Epoch: 97000 - Loss: 323.5715149832358\n",
      "Epoch: 98000 - Loss: 325.48879448869667\n",
      "Epoch: 99000 - Loss: 302.78549890378224\n"
     ]
    }
   ],
   "source": [
    "lr = 0.000001\n",
    "gamma = .9\n",
    "epochs = 100_000\n",
    "\n",
    "nS = 100\n",
    "nA = 100\n",
    "k = 50\n",
    "\n",
    "Q = PARAFAC(dims=[nS, nS, nA], k=k, scale=1.0)\n",
    "opt = torch.optim.Adam(Q.parameters(), lr=lr)\n",
    "for e in range(epochs):\n",
    "    l = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        states, states_next, actions, rewards = batch\n",
    "\n",
    "        # Update sequential\n",
    "        # opt.zero_grad()\n",
    "        # loss = torch.nn.MSELoss()(q_hat, q_target)\n",
    "        # loss.backward()\n",
    "        # opt.step()\n",
    "\n",
    "        # Update Alternating\n",
    "        for factor in Q.factors:\n",
    "            with torch.no_grad():\n",
    "                q_target = rewards + gamma * Q(states_next).max()\n",
    "            q_hat = Q(torch.cat((states, actions.unsqueeze(1)), dim=1))\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss = torch.nn.MSELoss()(q_hat, q_target)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for frozen_factor in Q.factors:\n",
    "                    if frozen_factor is not factor:\n",
    "                        frozen_factor.grad = None\n",
    "            opt.step()\n",
    "        l += loss.item()\n",
    "\n",
    "    if e % 1_000 == 0:\n",
    "        print(f\"Epoch: {e} - Loss: {l / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PendulumEnv(1, 1, 1)\n",
    "\n",
    "discretizer = Discretizer(\n",
    "        min_points_states=[-1, -5],\n",
    "        max_points_states=[1, 5],\n",
    "        bucket_states=[nS]*2,\n",
    "        min_points_actions=[-2],\n",
    "        max_points_actions=[2],\n",
    "        bucket_actions=[nA],\n",
    "    )\n",
    "\n",
    "H = 100\n",
    "E = 1000\n",
    "Gs = []\n",
    "\n",
    "for e in range(E):\n",
    "    G = 0\n",
    "    s, _ = env.reset()\n",
    "    s_idx = discretizer.get_state_index(s)\n",
    "    for h in range(H):\n",
    "        s_ten = torch.tensor(s_idx).unsqueeze(0)\n",
    "        a_idx = Q(s_ten).argmax().item()\n",
    "        a = discretizer.get_action_from_index(a_idx)\n",
    "        s, r, d, _, _ = env.step(a)\n",
    "        s_idx = discretizer.get_state_index(s)\n",
    "\n",
    "        G += r\n",
    "\n",
    "        if d:\n",
    "            break\n",
    "    Gs.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Gs, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(gs, m, l):\n",
    "    states, states_next, actions, rewards, tasks = [], [], [], [], []\n",
    "    for i, g in enumerate(gs):\n",
    "        env = PendulumEnv(g, m, l)\n",
    "        nS = 100\n",
    "        nA = 100\n",
    "\n",
    "        discretizer = Discretizer(\n",
    "            min_points_states=[-1, -5],\n",
    "            max_points_states=[1, 5],\n",
    "            bucket_states=[nS]*2,\n",
    "            min_points_actions=[-2],\n",
    "            max_points_actions=[2],\n",
    "            bucket_actions=[nA],\n",
    "        )\n",
    "\n",
    "        E = 10\n",
    "        H = 100\n",
    "\n",
    "        for e in range(E):\n",
    "            s, _ = env.reset()\n",
    "            s_idx = discretizer.get_state_index(s)\n",
    "            for h in range(H):\n",
    "                a_idx = np.random.choice(nA)\n",
    "                a = discretizer.get_action_from_index(a_idx)\n",
    "                sp, r, d, _, _ = env.step(a)\n",
    "                sp_idx = discretizer.get_state_index(sp)\n",
    "\n",
    "                states.append(s_idx)\n",
    "                states_next.append(sp_idx)\n",
    "                actions.append(a_idx)\n",
    "                rewards.append(r)\n",
    "                tasks.append(i)\n",
    "\n",
    "                if d:\n",
    "                    break\n",
    "\n",
    "                s = sp\n",
    "                s_idx = sp_idx\n",
    "\n",
    "    tasks = torch.tensor(tasks)\n",
    "    states = torch.tensor(states)\n",
    "    states_next = torch.tensor(states_next)\n",
    "    actions = torch.tensor(actions)\n",
    "    rewards = torch.tensor(rewards)\n",
    "\n",
    "    return tasks, states, states_next, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories(Dataset):\n",
    "    def __init__(self):\n",
    "        gs = [0.1, 1, 10, 100]\n",
    "        m = 1\n",
    "        l = 1\n",
    "        tasks, states, states_next, actions, rewards = sample_data(gs, m, l)\n",
    "\n",
    "        self.tasks = tasks\n",
    "        self.states = states\n",
    "        self.states_next = states_next\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.states.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tasks[idx], self.states[idx], self.states_next[idx], self.actions[idx], self.rewards[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = Trajectories()\n",
    "loader = DataLoader(trajectories, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 4264.891800937267\n",
      "Epoch: 1000 - Loss: 4312.508236939816\n",
      "Epoch: 2000 - Loss: 4363.143168093223\n",
      "Epoch: 3000 - Loss: 4361.578638183496\n",
      "Epoch: 4000 - Loss: 4295.000334273732\n",
      "Epoch: 5000 - Loss: 4251.042411854902\n",
      "Epoch: 6000 - Loss: 4345.75052791283\n",
      "Epoch: 7000 - Loss: 4318.006377316578\n",
      "Epoch: 8000 - Loss: 4173.088022012\n",
      "Epoch: 9000 - Loss: 4344.200474527158\n",
      "Epoch: 10000 - Loss: 4265.862440020188\n",
      "Epoch: 11000 - Loss: 4060.8207222646806\n",
      "Epoch: 12000 - Loss: 4090.3802930237957\n",
      "Epoch: 13000 - Loss: 4274.707057784721\n",
      "Epoch: 14000 - Loss: 4182.146805061789\n",
      "Epoch: 15000 - Loss: 4205.315065808115\n",
      "Epoch: 16000 - Loss: 4117.109653764917\n",
      "Epoch: 17000 - Loss: 3890.2998594808364\n",
      "Epoch: 18000 - Loss: 4292.9204152079155\n",
      "Epoch: 19000 - Loss: 4032.1116712659054\n",
      "Epoch: 20000 - Loss: 4223.844715636909\n",
      "Epoch: 21000 - Loss: 4235.757258481384\n",
      "Epoch: 22000 - Loss: 3939.6435126518054\n",
      "Epoch: 23000 - Loss: 4146.262750568264\n",
      "Epoch: 24000 - Loss: 4120.729102164222\n",
      "Epoch: 25000 - Loss: 4200.717414022972\n",
      "Epoch: 26000 - Loss: 3961.6128133065326\n",
      "Epoch: 27000 - Loss: 4113.9733918092825\n",
      "Epoch: 28000 - Loss: 4108.425128884414\n",
      "Epoch: 29000 - Loss: 3936.489796312316\n",
      "Epoch: 30000 - Loss: 4068.26874618774\n",
      "Epoch: 31000 - Loss: 4008.2519936599665\n",
      "Epoch: 32000 - Loss: 4100.090655572155\n",
      "Epoch: 33000 - Loss: 4043.6626156571106\n",
      "Epoch: 34000 - Loss: 3911.0260104432705\n",
      "Epoch: 35000 - Loss: 3968.679624741296\n",
      "Epoch: 36000 - Loss: 4066.2368357278033\n",
      "Epoch: 37000 - Loss: 3802.88120778816\n",
      "Epoch: 38000 - Loss: 4152.766557517183\n",
      "Epoch: 39000 - Loss: 3994.1611190842873\n",
      "Epoch: 40000 - Loss: 4145.11902346977\n",
      "Epoch: 41000 - Loss: 4001.3023195208075\n",
      "Epoch: 42000 - Loss: 4121.192891471342\n",
      "Epoch: 43000 - Loss: 3995.5652912593846\n",
      "Epoch: 44000 - Loss: 4045.764260070253\n",
      "Epoch: 45000 - Loss: 4058.345569357527\n",
      "Epoch: 46000 - Loss: 4043.204872772846\n",
      "Epoch: 47000 - Loss: 4001.013731716065\n",
      "Epoch: 48000 - Loss: 4072.6933542322936\n",
      "Epoch: 49000 - Loss: 4069.409498055416\n",
      "Epoch: 50000 - Loss: 4102.151691947707\n",
      "Epoch: 51000 - Loss: 3983.2021528364276\n",
      "Epoch: 52000 - Loss: 3963.785575089381\n",
      "Epoch: 53000 - Loss: 3704.6230422335702\n",
      "Epoch: 54000 - Loss: 4035.2587187933445\n",
      "Epoch: 55000 - Loss: 4082.648621862423\n",
      "Epoch: 56000 - Loss: 3921.955584552675\n",
      "Epoch: 57000 - Loss: 3924.701146740343\n",
      "Epoch: 58000 - Loss: 4042.8152641175266\n",
      "Epoch: 59000 - Loss: 3874.6436500105137\n",
      "Epoch: 60000 - Loss: 3972.911699679687\n",
      "Epoch: 61000 - Loss: 3734.648596731642\n",
      "Epoch: 62000 - Loss: 3844.7243466779382\n",
      "Epoch: 63000 - Loss: 4073.546308608464\n",
      "Epoch: 64000 - Loss: 3773.713186116288\n",
      "Epoch: 65000 - Loss: 3923.1797252756646\n",
      "Epoch: 66000 - Loss: 3862.3036063573895\n",
      "Epoch: 67000 - Loss: 4124.4998226967655\n",
      "Epoch: 68000 - Loss: 3983.313696205191\n",
      "Epoch: 69000 - Loss: 3922.9780254232796\n",
      "Epoch: 70000 - Loss: 3747.0024098418025\n",
      "Epoch: 71000 - Loss: 3832.4138049321477\n",
      "Epoch: 72000 - Loss: 4029.8432975192377\n",
      "Epoch: 73000 - Loss: 3887.080579038411\n",
      "Epoch: 74000 - Loss: 3986.368661361675\n",
      "Epoch: 75000 - Loss: 3819.3774552328\n",
      "Epoch: 76000 - Loss: 4019.6877586103355\n",
      "Epoch: 77000 - Loss: 3857.735491720805\n",
      "Epoch: 78000 - Loss: 3999.554372570314\n",
      "Epoch: 79000 - Loss: 3668.204560521663\n",
      "Epoch: 80000 - Loss: 3847.08804348034\n",
      "Epoch: 81000 - Loss: 3901.6119306068026\n",
      "Epoch: 82000 - Loss: 3774.96320559053\n",
      "Epoch: 83000 - Loss: 3694.218078085476\n",
      "Epoch: 84000 - Loss: 3891.739525711523\n",
      "Epoch: 85000 - Loss: 3921.7785646540424\n",
      "Epoch: 86000 - Loss: 3939.5477855424915\n",
      "Epoch: 87000 - Loss: 3810.460693738757\n",
      "Epoch: 88000 - Loss: 3774.5062612311244\n",
      "Epoch: 89000 - Loss: 3907.5962530144184\n",
      "Epoch: 90000 - Loss: 3870.5273392250724\n",
      "Epoch: 91000 - Loss: 3683.273736949032\n",
      "Epoch: 92000 - Loss: 3907.9453040954068\n",
      "Epoch: 93000 - Loss: 3788.1350915474004\n",
      "Epoch: 94000 - Loss: 3843.190030230181\n",
      "Epoch: 95000 - Loss: 3590.808791464765\n",
      "Epoch: 96000 - Loss: 3815.2129773258735\n",
      "Epoch: 97000 - Loss: 3977.479732485181\n",
      "Epoch: 98000 - Loss: 3825.3020396000143\n",
      "Epoch: 99000 - Loss: 3863.3721114698956\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0000001\n",
    "gamma = .9\n",
    "epochs = 100_000\n",
    "\n",
    "nT = 4\n",
    "nS = 100\n",
    "nA = 100\n",
    "k = 50\n",
    "\n",
    "# Q = PARAFAC(dims=[nT, nS, nS, nA], k=k, scale=1.0)\n",
    "opt = torch.optim.Adam(Q.parameters(), lr=lr)\n",
    "for e in range(epochs):\n",
    "    l = 0\n",
    "    for _, batch in enumerate(loader):\n",
    "        tasks, states, states_next, actions, rewards = batch\n",
    "\n",
    "        # Update Alternating\n",
    "        for factor in Q.factors:\n",
    "            idx_target = torch.cat((tasks.unsqueeze(1), states), dim=1)\n",
    "            idx_hat = torch.cat((tasks.unsqueeze(1), states, actions.unsqueeze(1)), dim=1)\n",
    "            with torch.no_grad():\n",
    "                q_target = rewards + gamma * Q(idx_target).max()\n",
    "            q_hat = Q(idx_hat)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss = torch.nn.MSELoss()(q_hat, q_target)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for frozen_factor in Q.factors:\n",
    "                    if frozen_factor is not factor:\n",
    "                        frozen_factor.grad = None\n",
    "            opt.step()\n",
    "        l += loss.item()\n",
    "\n",
    "    if e % 1_000 == 0:\n",
    "        print(f\"Epoch: {e} - Loss: {l / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PendulumEnv(1, 1, 1)\n",
    "\n",
    "discretizer = Discretizer(\n",
    "        min_points_states=[-1, -5],\n",
    "        max_points_states=[1, 5],\n",
    "        bucket_states=[nS]*2,\n",
    "        min_points_actions=[-2],\n",
    "        max_points_actions=[2],\n",
    "        bucket_actions=[nA],\n",
    "    )\n",
    "\n",
    "H = 100\n",
    "E = 1000\n",
    "Gs = []\n",
    "\n",
    "for e in range(E):\n",
    "    G = 0\n",
    "    s, _ = env.reset()\n",
    "    s_idx = tuple([1] + list(discretizer.get_state_index(s)))\n",
    "    for h in range(H):\n",
    "        s_ten = torch.tensor(s_idx).unsqueeze(0)\n",
    "        a_idx = Q(s_ten).argmax().item()\n",
    "        a = discretizer.get_action_from_index(a_idx)\n",
    "        s, r, d, _, _ = env.step(a)\n",
    "        s_idx = tuple([1] + list(discretizer.get_state_index(s)))\n",
    "\n",
    "        G += r\n",
    "\n",
    "        if d:\n",
    "            break\n",
    "    Gs.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Gs, bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
