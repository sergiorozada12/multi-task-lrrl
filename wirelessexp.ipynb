{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.environments import WirelessCommunicationsEnv\n",
    "from src.utils import Discretizer\n",
    "from src.sampler import PendulumTrajectorySampler, EpsilonGreedyPendulumTrajectorySampler\n",
    "from src.trainer import QNetworkTrainer, QNetworkTester\n",
    "from src.models import PARAFAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [5, 10, 15, 20]\n",
    "\n",
    "envs = [WirelessCommunicationsEnv(\n",
    "    T=1_000,\n",
    "    K=3,\n",
    "    snr_max=10,\n",
    "    snr_min=2,\n",
    "    snr_autocorr=0.7,\n",
    "    P_occ=np.array(\n",
    "        [  \n",
    "            [0.4, 0.6],\n",
    "            [0.6, 0.4],\n",
    "        ]\n",
    "    ),\n",
    "    occ_initial=[1, 1, 1],\n",
    "    batt_harvest=1.0, \n",
    "    P_harvest=0.2, \n",
    "    batt_initial=5,\n",
    "    batt_max_capacity=10,  \n",
    "    batt_weight=1.0, \n",
    "    queue_initial=10,\n",
    "    queue_arrival=5,\n",
    "    queue_max_capacity=20,\n",
    "    t_queue_arrival=ts[i],\n",
    "    queue_weight=0.2,\n",
    "    loss_busy=0.8,  \n",
    ") for i in range(len(ts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = Discretizer(\n",
    "    min_points_states=[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    max_points_states=[20, 20, 10, 1, 1, 1, 20, 10],\n",
    "    bucket_states=[10, 10, 10, 2, 2, 2, 10, 10],\n",
    "    min_points_actions=[0, 0, 0],\n",
    "    max_points_actions=[2, 2, 2],\n",
    "    bucket_actions=[10, 10, 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS = [10, 10, 10, 2, 2, 2, 10, 10]\n",
    "nA = [10, 10, 10]\n",
    "nT = 4\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(states_next, rewards, Q, tasks=None):\n",
    "    if tasks is not None:\n",
    "        idx_target = torch.cat((tasks.unsqueeze(1), states_next), dim=1)\n",
    "    else:\n",
    "        idx_target = states_next\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_target = rewards + gamma * Q(idx_target).max(dim=1).values\n",
    "\n",
    "    return q_target\n",
    "\n",
    "def create_idx_hat(states, actions, tasks=None):\n",
    "    if tasks is not None:\n",
    "        idx_hat = torch.cat((tasks.unsqueeze(1), states, actions), dim=1)\n",
    "    else:\n",
    "        idx_hat = torch.cat((states, actions), dim=1)\n",
    "    return idx_hat\n",
    "\n",
    "def update_model(s_idx, sp_idx, a_idx, r, Q, opt, tasks=None):\n",
    "    for factor in Q.factors:\n",
    "        q_target = create_target(sp_idx, r, Q, tasks)\n",
    "        idx_hat = create_idx_hat(s_idx, a_idx, tasks)\n",
    "        q_hat = Q(idx_hat)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = torch.nn.MSELoss()(q_hat, q_target)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for frozen_factor in Q.factors:\n",
    "                if frozen_factor is not factor:\n",
    "                    frozen_factor.grad = None\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "def select_random_action() -> np.ndarray:\n",
    "        a_idx = tuple(np.random.randint(discretizer.bucket_actions).tolist())\n",
    "        return discretizer.get_action_from_index(a_idx), a_idx\n",
    "\n",
    "def select_greedy_action(Q, s: np.ndarray) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        s_idx = np.concatenate([discretizer.get_state_index(s)])\n",
    "        a_idx_flat = Q(s_idx).argmax().detach().item()\n",
    "        a_idx = np.unravel_index(a_idx_flat, discretizer.bucket_actions)\n",
    "        return discretizer.get_action_from_index(a_idx), a_idx\n",
    "\n",
    "def select_action(Q, s: np.ndarray, epsilon: float) -> np.ndarray:\n",
    "    if np.random.rand() < epsilon:\n",
    "        return select_random_action()\n",
    "    return select_greedy_action(Q, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mono-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 1000\n",
    "H = 1000\n",
    "lr = 0.01\n",
    "eps = 1.0\n",
    "eps_decay = 0.99999\n",
    "eps_min = 0.1\n",
    "\n",
    "k = 20\n",
    "n_upd = nT\n",
    "\n",
    "env_id = 1\n",
    "\n",
    "def run_test_episode(Q, env_idx):\n",
    "    with torch.no_grad():\n",
    "        G = 0\n",
    "        s, _ = envs[env_idx].reset()\n",
    "        s_idx = torch.tensor(discretizer.get_state_index(s)).unsqueeze(0)\n",
    "        for h in range(H):\n",
    "            a_idx = Q(s_idx).argmax().item()\n",
    "            a = discretizer.get_action_from_index(a_idx)\n",
    "            a_idx = torch.tensor(a_idx).unsqueeze(0)\n",
    "            sp, r, d, _, _ = envs[env_idx].step(a)\n",
    "            sp_idx = torch.tensor(discretizer.get_state_index(sp)).unsqueeze(0)\n",
    "\n",
    "            G += r\n",
    "\n",
    "            if d:\n",
    "                break\n",
    "\n",
    "            s = sp\n",
    "            s_idx = sp_idx\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - Return: -128.49145094824613 - 0.9940179342332267"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m s_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(discretizer\u001b[38;5;241m.\u001b[39mget_state_index(s))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(H):\n\u001b[0;32m----> 9\u001b[0m     a, a_idx \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     a_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(a_idx)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m     sp, r, d, _, _ \u001b[38;5;241m=\u001b[39m envs[env_id]\u001b[38;5;241m.\u001b[39mstep(a)\n",
      "Cell \u001b[0;32mIn[39], line 50\u001b[0m, in \u001b[0;36mselect_action\u001b[0;34m(Q, s, epsilon)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m epsilon:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m select_random_action()\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_greedy_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 42\u001b[0m, in \u001b[0;36mselect_greedy_action\u001b[0;34m(Q, s)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_greedy_action\u001b[39m(Q, s: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 42\u001b[0m         s_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mdiscretizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[1;32m     43\u001b[0m         a_idx_flat \u001b[38;5;241m=\u001b[39m Q(s_idx)\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     44\u001b[0m         a_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munravel_index(a_idx_flat, discretizer\u001b[38;5;241m.\u001b[39mbucket_actions)\n",
      "File \u001b[0;32m~/Repositories/multi-task-lrrl/src/utils.py:33\u001b[0m, in \u001b[0;36mDiscretizer.get_state_index\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     31\u001b[0m state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(state, a_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_points_states, a_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_points_states)\n\u001b[1;32m     32\u001b[0m scaling \u001b[38;5;241m=\u001b[39m (state \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_points_states) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrange_states\n\u001b[0;32m---> 33\u001b[0m state_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(state_idx\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "Gs = []\n",
    "Q = PARAFAC(dims=nS + nA, k=k, scale=0.1)\n",
    "opt = torch.optim.Adamax(Q.parameters(), lr=lr)\n",
    "ds = 0\n",
    "for episode in range(E):\n",
    "    s, _ = envs[env_id].reset()\n",
    "    s_idx = torch.tensor(discretizer.get_state_index(s)).unsqueeze(0)\n",
    "    for h in range(H):\n",
    "        a, a_idx = select_action(Q, s_idx, eps)\n",
    "        a_idx = torch.tensor(a_idx).unsqueeze(0)\n",
    "        sp, r, d, _, _ = envs[env_id].step(a)\n",
    "        sp_idx = torch.tensor(discretizer.get_state_index(sp)).unsqueeze(0)\n",
    "\n",
    "        for _ in range(n_upd):\n",
    "            update_model(s_idx, sp_idx, a_idx, r, Q, opt)\n",
    "\n",
    "        s = sp\n",
    "        s_idx = sp_idx\n",
    "        eps = max(eps*eps_decay, eps_min)\n",
    "\n",
    "        # if h % 10 == 0:\n",
    "    G = run_test_episode(Q, env_id)\n",
    "    Gs.append(G)\n",
    "    print(f\"\\rEpoch: {episode} - Return: {G} - {eps}\", end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, _ = envs[0].reset()\n",
    "s_idx = torch.tensor(discretizer.get_state_index(s)).unsqueeze(0)\n",
    "a, a_idx = select_action(Q, s_idx, eps)\n",
    "a_idx = torch.tensor(a_idx).unsqueeze(0)\n",
    "idx = s_idx\n",
    "idx = torch.cat((s_idx, a_idx), dim=1)\n",
    "q = Q(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.2449e-12], dtype=torch.float64, grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
